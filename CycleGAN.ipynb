{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CycleGAN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOv61TLexi9fI6quC+/jCT/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5f8ec9146f884a1492d122b76740cce1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a9df64e6fedc418396bc8aab6624f6ac","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e673ebfc4223421bb149aa4e508f8a97","IPY_MODEL_4c0ced0d45c74eecbd85522e6209789b"]}},"a9df64e6fedc418396bc8aab6624f6ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e673ebfc4223421bb149aa4e508f8a97":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5489212c8e79447a9489d7f392a9dfe6","_dom_classes":[],"description":"  3%","_model_name":"IntProgressModel","bar_style":"","max":268,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_113746c232da44689dfc7e0e78081d4f"}},"4c0ced0d45c74eecbd85522e6209789b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b80475157da84a6c8803ef4116edb89c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9/268 [01:24&lt;40:42,  9.43s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_29c96a60ae434d9f8c740a8ce77cdaf2"}},"5489212c8e79447a9489d7f392a9dfe6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"113746c232da44689dfc7e0e78081d4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b80475157da84a6c8803ef4116edb89c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"29c96a60ae434d9f8c740a8ce77cdaf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Q_akPBkSaN8p","colab_type":"text"},"source":["# Import"]},{"cell_type":"code","metadata":{"id":"xWGAOrygvb37","colab_type":"code","colab":{}},"source":["import torch\n","from torch import nn\n","from torchsummary import summary\n","import torch.nn.functional as F\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rTvAAsvfxvT1","colab_type":"code","colab":{}},"source":["def conv(n_in, n_filters, kernel_size, stride, bias=False):\n","    return nn.Conv2d(n_in, n_filters, kernel_size=kernel_size, stride=stride, padding=kernel_size // 2, bias=bias)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6cS946Mqna84","colab_type":"code","colab":{}},"source":["def inv_conv(n_in, n_filters, kernel_size, stride, bias=False):\n","    return nn.ConvTranspose2d(n_in, n_filters, kernel_size=kernel_size, stride=stride, padding=1, output_padding=1, bias=bias)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5YnnHUWZ1Q0v","colab_type":"code","colab":{}},"source":["def requires_grad(module, status):\n","  for p in list(module.parameters()):\n","    p.requires_grad = status"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZp5O7ywxfoj","colab_type":"code","colab":{}},"source":["device = torch.device('cuda')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tiuAeidVaTwc","colab_type":"text"},"source":["# Discriminator"]},{"cell_type":"code","metadata":{"id":"I2KwF-EmzVC_","colab_type":"code","colab":{}},"source":["def init_cnn(m):\n","    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n","    if isinstance(m, (nn.Conv2d, nn.Linear)): nn.init.kaiming_normal_(m.weight)\n","    for l in m.children(): init_cnn(l)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7T6tUJ1Y4CjP","colab_type":"code","colab":{}},"source":["def activation(act):\n","  if act == 'leakyrelu':\n","    return nn.LeakyReLU(negative_slope=0.2)\n","  elif act == 'tanh':\n","    return nn.Tanh()\n","  else:\n","    return nn.ReLU()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S2nbjsgizhVW","colab_type":"code","colab":{}},"source":["def conv_layer(n_in, n_filters, kernel_size, stride, do_norm=True, do_act=True, act='relu'):\n","    layers = [conv(n_in, n_filters, kernel_size, stride)]\n","    if do_norm: layers.append(nn.InstanceNorm2d(n_filters))\n","    if do_act: layers.append(activation(act))\n","    return nn.Sequential(*layers)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvNWFq6rnMjc","colab_type":"code","colab":{}},"source":["def inv_conv_layer(n_in, n_filters, kernel_size, stride, do_norm=True, do_act=True, act='relu'):\n","  layers = [inv_conv(n_in, n_filters, kernel_size, stride)]\n","  if do_norm: layers.append(nn.InstanceNorm2d(n_filters))\n","  if do_act: layers.append(activation(act))\n","  return nn.Sequential(*layers)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbuyZ89lwrJP","colab_type":"code","colab":{}},"source":["class Discriminator(nn.Module):\n","  def __init__(self, input_shape):\n","    super().__init__()\n","    n_in = input_shape[0]\n","    self.loss = nn.MSELoss()\n","    self.model = nn.Sequential(\n","        conv_layer(n_in, 64, 3, 2, act='leakyrelu', do_norm=False),\n","        conv_layer(64, 128, 3, 2, act='leakyrelu'),\n","        conv_layer(128, 256, 3, 2, act='leakyrelu'),\n","        conv_layer(256, 512, 3, 2, act='leakyrelu'),\n","        conv_layer(512, 512, 3, 1, act='leakyrelu'),\n","        conv(512, 1, 3, 1)\n","    )\n","    init_cnn(self.model)\n","\n","  def forward(self, x):\n","    return self.model(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmGKOkRs8MdW","colab_type":"code","outputId":"4f3ebd26-bf85-4577-fac0-52fb47bc7a64","executionInfo":{"status":"ok","timestamp":1585812224789,"user_tz":-120,"elapsed":1526,"user":{"displayName":"Hugo Soulignac","photoUrl":"","userId":"11865517890955263354"}},"colab":{"base_uri":"https://localhost:8080/","height":487}},"source":["input_shape = (3, 256, 256)\n","disc = Discriminator(input_shape)\n","disc.to(device=device)\n","summary(disc, input_shape)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 128, 128]           1,728\n","         LeakyReLU-2         [-1, 64, 128, 128]               0\n","            Conv2d-3          [-1, 128, 64, 64]          73,728\n","    InstanceNorm2d-4          [-1, 128, 64, 64]               0\n","         LeakyReLU-5          [-1, 128, 64, 64]               0\n","            Conv2d-6          [-1, 256, 32, 32]         294,912\n","    InstanceNorm2d-7          [-1, 256, 32, 32]               0\n","         LeakyReLU-8          [-1, 256, 32, 32]               0\n","            Conv2d-9          [-1, 512, 16, 16]       1,179,648\n","   InstanceNorm2d-10          [-1, 512, 16, 16]               0\n","        LeakyReLU-11          [-1, 512, 16, 16]               0\n","           Conv2d-12          [-1, 512, 16, 16]       2,359,296\n","   InstanceNorm2d-13          [-1, 512, 16, 16]               0\n","        LeakyReLU-14          [-1, 512, 16, 16]               0\n","           Conv2d-15            [-1, 1, 16, 16]           4,608\n","================================================================\n","Total params: 3,913,920\n","Trainable params: 3,913,920\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.75\n","Forward/backward pass size (MB): 40.00\n","Params size (MB): 14.93\n","Estimated Total Size (MB): 55.68\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ljYnjgr3aYh1","colab_type":"text"},"source":["# Generator"]},{"cell_type":"code","metadata":{"id":"lVkXC1leabvj","colab_type":"code","colab":{}},"source":["class ResBlock(nn.Module):\n","  def __init__(self, n_in, n_filters):\n","    super().__init__()\n","    self.convs = nn.Sequential(\n","        conv_layer(n_in, n_filters, 3, 1, act='relu'),\n","        conv_layer(n_filters, n_filters, 3, 1, do_act=False)\n","    )\n","    self.downsample = None\n","    self.relu = nn.ReLU()\n","    if n_in != n_filters:\n","      self.downsample = conv_layer(n_in, n_filters, 3, 1, do_act=False)\n","      init_cnn(self.downsample)\n","\n","    init_cnn(self.convs)\n","\n","  def forward(self, x):\n","    residual = x\n","    y = self.convs(x)\n","    if self.downsample:\n","      residual = self.downsample(x)\n","    return self.relu(y + residual)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PqoGgZBgd6js","colab_type":"code","outputId":"a16fb7ee-1cbd-423a-fe27-935c76c13228","executionInfo":{"status":"ok","timestamp":1585812258051,"user_tz":-120,"elapsed":1060,"user":{"displayName":"Hugo Soulignac","photoUrl":"","userId":"11865517890955263354"}},"colab":{"base_uri":"https://localhost:8080/","height":370}},"source":["res_block = ResBlock(3, 64)\n","res_block.to(device=device)\n","summary(res_block, (input_shape))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 256, 256]           1,728\n","    InstanceNorm2d-2         [-1, 64, 256, 256]               0\n","              ReLU-3         [-1, 64, 256, 256]               0\n","            Conv2d-4         [-1, 64, 256, 256]          36,864\n","    InstanceNorm2d-5         [-1, 64, 256, 256]               0\n","            Conv2d-6         [-1, 64, 256, 256]           1,728\n","    InstanceNorm2d-7         [-1, 64, 256, 256]               0\n","              ReLU-8         [-1, 64, 256, 256]               0\n","================================================================\n","Total params: 40,320\n","Trainable params: 40,320\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.75\n","Forward/backward pass size (MB): 256.00\n","Params size (MB): 0.15\n","Estimated Total Size (MB): 256.90\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U5YxRnvFj-_m","colab_type":"code","colab":{}},"source":["class Generator(nn.Module):\n","  def __init__(self, input_shape, n_resblock=9):\n","    super().__init__()\n","    n_in = input_shape[0]\n","    self.loss = nn.MSELoss()\n","    res_blocks = [ResBlock(256, 256) for _ in range(n_resblock)]\n","    self.model = nn.Sequential(\n","        conv_layer(n_in, 64, 7, 1, act='relu'),\n","        conv_layer(64, 128, 3, 2, act='relu'),\n","        conv_layer(128, 256, 3, 2, act='relu'),\n","\n","        *res_blocks,\n","\n","        inv_conv_layer(256, 128, 3, 2, act='relu'),\n","        inv_conv_layer(128, 64, 3, 2, act='relu'),\n","        conv_layer(64, 3, 7, 1, act='tanh')\n","    )\n","    init_cnn(self.model)\n","\n","  def forward(self, x):\n","    return self.model(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"koNKjmz4o8NN","colab_type":"code","outputId":"97883d1d-598e-4934-d11e-809d02cb5f7e","executionInfo":{"status":"ok","timestamp":1585812279990,"user_tz":-120,"elapsed":1612,"user":{"displayName":"Hugo Soulignac","photoUrl":"","userId":"11865517890955263354"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["gen = Generator(input_shape)\n","gen.to(device=device)\n","summary(gen, (input_shape))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 256, 256]           9,408\n","    InstanceNorm2d-2         [-1, 64, 256, 256]               0\n","              ReLU-3         [-1, 64, 256, 256]               0\n","            Conv2d-4        [-1, 128, 128, 128]          73,728\n","    InstanceNorm2d-5        [-1, 128, 128, 128]               0\n","              ReLU-6        [-1, 128, 128, 128]               0\n","            Conv2d-7          [-1, 256, 64, 64]         294,912\n","    InstanceNorm2d-8          [-1, 256, 64, 64]               0\n","              ReLU-9          [-1, 256, 64, 64]               0\n","           Conv2d-10          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-11          [-1, 256, 64, 64]               0\n","             ReLU-12          [-1, 256, 64, 64]               0\n","           Conv2d-13          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-14          [-1, 256, 64, 64]               0\n","             ReLU-15          [-1, 256, 64, 64]               0\n","         ResBlock-16          [-1, 256, 64, 64]               0\n","           Conv2d-17          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-18          [-1, 256, 64, 64]               0\n","             ReLU-19          [-1, 256, 64, 64]               0\n","           Conv2d-20          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-21          [-1, 256, 64, 64]               0\n","             ReLU-22          [-1, 256, 64, 64]               0\n","         ResBlock-23          [-1, 256, 64, 64]               0\n","           Conv2d-24          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-25          [-1, 256, 64, 64]               0\n","             ReLU-26          [-1, 256, 64, 64]               0\n","           Conv2d-27          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-28          [-1, 256, 64, 64]               0\n","             ReLU-29          [-1, 256, 64, 64]               0\n","         ResBlock-30          [-1, 256, 64, 64]               0\n","           Conv2d-31          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-32          [-1, 256, 64, 64]               0\n","             ReLU-33          [-1, 256, 64, 64]               0\n","           Conv2d-34          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-35          [-1, 256, 64, 64]               0\n","             ReLU-36          [-1, 256, 64, 64]               0\n","         ResBlock-37          [-1, 256, 64, 64]               0\n","           Conv2d-38          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-39          [-1, 256, 64, 64]               0\n","             ReLU-40          [-1, 256, 64, 64]               0\n","           Conv2d-41          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-42          [-1, 256, 64, 64]               0\n","             ReLU-43          [-1, 256, 64, 64]               0\n","         ResBlock-44          [-1, 256, 64, 64]               0\n","           Conv2d-45          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-46          [-1, 256, 64, 64]               0\n","             ReLU-47          [-1, 256, 64, 64]               0\n","           Conv2d-48          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-49          [-1, 256, 64, 64]               0\n","             ReLU-50          [-1, 256, 64, 64]               0\n","         ResBlock-51          [-1, 256, 64, 64]               0\n","           Conv2d-52          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-53          [-1, 256, 64, 64]               0\n","             ReLU-54          [-1, 256, 64, 64]               0\n","           Conv2d-55          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-56          [-1, 256, 64, 64]               0\n","             ReLU-57          [-1, 256, 64, 64]               0\n","         ResBlock-58          [-1, 256, 64, 64]               0\n","           Conv2d-59          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-60          [-1, 256, 64, 64]               0\n","             ReLU-61          [-1, 256, 64, 64]               0\n","           Conv2d-62          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-63          [-1, 256, 64, 64]               0\n","             ReLU-64          [-1, 256, 64, 64]               0\n","         ResBlock-65          [-1, 256, 64, 64]               0\n","           Conv2d-66          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-67          [-1, 256, 64, 64]               0\n","             ReLU-68          [-1, 256, 64, 64]               0\n","           Conv2d-69          [-1, 256, 64, 64]         589,824\n","   InstanceNorm2d-70          [-1, 256, 64, 64]               0\n","             ReLU-71          [-1, 256, 64, 64]               0\n","         ResBlock-72          [-1, 256, 64, 64]               0\n","  ConvTranspose2d-73        [-1, 128, 128, 128]         294,912\n","   InstanceNorm2d-74        [-1, 128, 128, 128]               0\n","             ReLU-75        [-1, 128, 128, 128]               0\n","  ConvTranspose2d-76         [-1, 64, 256, 256]          73,728\n","   InstanceNorm2d-77         [-1, 64, 256, 256]               0\n","             ReLU-78         [-1, 64, 256, 256]               0\n","           Conv2d-79          [-1, 3, 256, 256]           9,408\n","   InstanceNorm2d-80          [-1, 3, 256, 256]               0\n","             Tanh-81          [-1, 3, 256, 256]               0\n","================================================================\n","Total params: 11,372,928\n","Trainable params: 11,372,928\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.75\n","Forward/backward pass size (MB): 820.50\n","Params size (MB): 43.38\n","Estimated Total Size (MB): 864.63\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lmuFVsr0sNxU","colab_type":"text"},"source":["# Cycle-GAN"]},{"cell_type":"code","metadata":{"id":"KdVF5JYm5des","colab_type":"code","colab":{}},"source":["def real_mse_loss(d_out): # how close is the produced output from being real?\n","  return torch.mean((d_out - 1) ** 2)\n","\n","def fake_mse_loss(d_out): # how close is the produced output from being fake?\n","  return torch.mean(d_out ** 2)\n","\n","def cycle_consistency_loss(real_im, reconstructed_im, lambda_weight): # calculate reconstruction loss and return weighted loss\n","  loss = torch.mean(torch.abs(real_im - reconstructed_im))\n","  return loss * lambda_weight"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7VCw0XtVzkTL","colab_type":"text"},"source":["# Trainer"]},{"cell_type":"code","metadata":{"id":"Hx0GbSjIzmQ_","colab_type":"code","colab":{}},"source":["from tqdm.notebook import tqdm\n","\n","class GANTrainer:\n","  def __init__(self, dataloader_a, dataloader_b, input_shape):\n","    # Dataloaders\n","    self.dataloader_a, self.dataloader_b = dataloader_a, dataloader_b\n","    \n","    # Models\n","    self.gen_a, self.gen_b = Generator(input_shape), Generator(input_shape)\n","    self.disc_a, self.disc_b = Discriminator(input_shape), Discriminator(input_shape)\n","    self.send_to_gpu()\n","\n","    # Optimizer\n","    gen_params = list(self.gen_a.parameters()) + list(self.gen_b.parameters())\n","    self.gen_opt = torch.optim.Adam(gen_params, betas=(0.5, 0.99))\n","    self.disc_a_opt = torch.optim.Adam(self.disc_a.parameters(), betas=(0.5, 0.99))\n","    self.disc_b_opt = torch.optim.Adam(self.disc_b.parameters(), betas=(0.5, 0.99))\n","\n","  def send_to_gpu(self):\n","    self.gen_a.to(device=device)\n","    self.gen_b.to(device=device)\n","    self.disc_a.to(device=device)\n","    self.disc_b.to(device=device)\n","\n","  def set_trainable(self, disc_a=False, disc_b=False):\n","    gen = (not disc_a) and (not disc_b)\n","    requires_grad(self.gen_a, gen)\n","    requires_grad(self.gen_b, gen)\n","    requires_grad(self.disc_a, disc_a)\n","    requires_grad(self.disc_b, disc_b)\n","\n","  def fit(self, nb_epochs=1):\n","    for epoch in range(nb_epochs):\n","      print(\"EPOCH {}\".format(epoch + 1))\n","      self.one_epoch()\n","\n","  def one_epoch(self):\n","    all_loss_disc_a, all_loss_disc_b, all_loss_cycle, count = 0.0, 0.0, 0.0, 0.0\n","    for real_a, real_b in tqdm(zip(self.dataloader_a, self.dataloader_b), total=len(self.dataloader_a)):\n","      real_a, real_b = real_a.cuda(), real_b.cuda()\n","      real_a, real_b = real_a.to(device=device, dtype=torch.float), real_b.to(device=device, dtype=torch.float)\n","\n","      # Discriminators training\n","      ## disc_a\n","      self.disc_a_opt.zero_grad()\n","      real_disc_a_loss = real_mse_loss(self.disc_a(real_a))\n","      fake_disc_a_loss = fake_mse_loss(self.disc_a(self.gen_a(real_b)))\n","      disc_a_loss = real_disc_a_loss + fake_disc_a_loss\n","      disc_a_loss.backward()\n","      self.disc_a_opt.step()\n","      all_loss_disc_a += disc_a_loss\n","\n","      ## disc_b\n","      self.disc_b_opt.zero_grad()\n","      real_disc_b_loss = real_mse_loss(self.disc_b(real_b))\n","      fake_disc_b_loss = fake_mse_loss(self.disc_b(self.gen_b(real_a)))\n","      disc_b_loss = real_disc_b_loss + fake_disc_b_loss\n","      disc_b_loss.backward()\n","      self.disc_b_opt.step()\n","      all_loss_disc_b += disc_b_loss\n","\n","      # Generators training\n","      self.gen_opt.zero_grad()\n","      out_1 = self.gen_a(real_b)\n","      loss_1 = real_mse_loss(self.disc_a(out_1))\n","      out_2 = self.gen_b(out_1)\n","      loss_2 = cycle_consistency_loss(real_im=real_b, reconstructed_im=out_2, lambda_weight=10.0)\n","\n","      out_3 = self.gen_b(real_a)\n","      loss_3 = real_mse_loss(self.disc_b(out_3))\n","      out_4 = self.gen_a(out_3)\n","      loss_4 = cycle_consistency_loss(real_im=real_a, reconstructed_im=out_4, lambda_weight=10.0)\n","\n","      gen_total_loss = loss_1 + loss_2 + loss_3 + loss_4\n","      gen_total_loss.backward()\n","      self.gen_opt.step()\n","      all_loss_cycle += gen_total_loss\n","\n","      count += real_a.shape[0]\n","\n","    print(\"Loss:\")\n","    print(\"Discriminator A --> {:.4f}\".format(all_loss_disc_a / count))\n","    print(\"Discriminator B --> {:.4f}\".format(all_loss_disc_b / count))\n","    print(\"Cycle           --> {:.4f} \\n\".format(all_loss_cycle / count))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aXjR--EWb0hy","colab_type":"text"},"source":["# Data"]},{"cell_type":"code","metadata":{"id":"Ksu1mz0Ab1wD","colab_type":"code","outputId":"919c3dfd-8fe7-4fb9-b04e-353709237988","executionInfo":{"status":"ok","timestamp":1585816799937,"user_tz":-120,"elapsed":28501,"user":{"displayName":"Hugo Soulignac","photoUrl":"","userId":"11865517890955263354"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RlZ5i62mcYVj","colab_type":"code","colab":{}},"source":["root_path = os.path.join(os.getcwd(), 'drive', 'My Drive', 'Datasets')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"em24V_SJc9WK","colab_type":"code","colab":{}},"source":["zip_path = os.path.join(root_path, 'monet2photo.zip')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uum2pyq8dIA_","colab_type":"code","colab":{}},"source":["import zipfile\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(root_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NqrC6Dlldpvv","colab_type":"code","colab":{}},"source":["data_path = os.path.join(root_path, 'monet2photo', 'monet2photo')\n","train_a_path = os.path.join(data_path, 'trainA')\n","train_b_path = os.path.join(data_path, 'trainB')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LynuDXwieZtz","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","from skimage import io, transform\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PITuQHgAhvTz","colab_type":"code","colab":{}},"source":["class DomainDataset(Dataset):\n","  def __init__(self, train_path, transform_ops=None):\n","    self.train_path, self.transform_ops = train_path, transform_ops\n","    self.images = os.listdir(self.train_path)\n","    random.shuffle(self.images)\n","    self.length = len(self.images)\n","\n","  def __len__(self):\n","    return self.length\n","\n","  def __getitem__(self, idx):\n","    img_path = os.path.join(self.train_path, self.images[idx])\n","    img = io.imread(img_path)\n","\n","    if self.transform_ops:\n","      img = self.transform_ops(img)\n","\n","    return img\n","\n","  def set_length(self, length):\n","    self.length = length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gANAbjlokgQB","colab_type":"code","colab":{}},"source":["class ToTensor(object):\n","  def __call__(self, sample):\n","    image = sample.transpose((2, 0, 1)) / 255.0\n","    return torch.from_numpy(image)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yG2RelefgT3q","colab_type":"code","colab":{}},"source":["tfms = transforms.Compose([ToTensor()])\n","ds_a = DomainDataset(train_a_path, transform_ops=tfms)\n","ds_b = DomainDataset(train_b_path, transform_ops=tfms)\n","ds_a.set_length(min(len(ds_a), len(ds_b)))\n","ds_b.set_length(min(len(ds_a), len(ds_b)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"axBRcTsimLsD","colab_type":"code","colab":{}},"source":["batch_size = 4\n","train_a_loader = DataLoader(dataset=ds_a, batch_size=batch_size, shuffle=True)\n","train_b_loader = DataLoader(dataset=ds_b, batch_size=batch_size, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g7TGmGjanqUE","colab_type":"text"},"source":["# Putting everything together"]},{"cell_type":"code","metadata":{"id":"H3M-m0_anvFb","colab_type":"code","colab":{}},"source":["input_shape = (3, 256, 256)\n","trainer = GANTrainer(train_a_loader, train_b_loader, input_shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9b7nVOGquWqI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["5f8ec9146f884a1492d122b76740cce1","a9df64e6fedc418396bc8aab6624f6ac","e673ebfc4223421bb149aa4e508f8a97","4c0ced0d45c74eecbd85522e6209789b","5489212c8e79447a9489d7f392a9dfe6","113746c232da44689dfc7e0e78081d4f","b80475157da84a6c8803ef4116edb89c","29c96a60ae434d9f8c740a8ce77cdaf2"]},"outputId":"d6e0eb7e-de99-472a-d828-a32ad7ddd46c"},"source":["trainer.fit(1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["EPOCH 1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f8ec9146f884a1492d122b76740cce1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=268), HTML(value='')))"]},"metadata":{"tags":[]}}]}]}